---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---

{%- include header.html -%}


<img src="images/acids_white_bg.png" alt="ACIDS" width="200" style="float:left;margin:0px 30px">

<p align="justify">
The Artificial Creative Intelligence and Data Science (ACIDS) group at IRCAM aims to model musical creativity by extending probabilistic learning approaches to the use of multivariate and multimodal time series. Our main object of study lies in the properties and perception of musical synthesis and artificial creativity. In this context, we experiment with deep AI models applied to creative materials, aiming to develop artificial creative intelligence.
</p>


Here you can find all informations on 
- Our different [open-source projects](projects)
- The [team](team) behind all these wonders
- Different [workshops](workshops) that we organize

Our highlight [projects]

- [Neurorack]() // the first deep AI-based eurorack synthesizer
- [RAVE]() // a VST that allows to transform your voice into a violin or a darbouka (or any sound in the world) in real-time.
- [FlowSynth]() // a learning-based device that allows to travel auditory spaces of synthesizers, simply by moving your hand

Our work aims to decipher both complex temporal relationships, and also analyze musical information located at the exact intersection between symbolic (musical writing) and signal (audio recording) representations. Our team has produced many prototypes of innovative instruments and musical pieces in collaborations with renowned composers. 
